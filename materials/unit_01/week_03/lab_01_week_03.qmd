---
title: "Week 7 Lab: Forecasting and Prediction Intervals"
format: 
  html:
    theme: zephyr
    toc: true
---


![](includes/generic_forecasting.webp)

::: {style="font-size: 1.5em"}
This Lab Contributes to Course Objectives: 1, 2, 3, 4, 7, 8
:::

## Learning Objectives R

- Understand the statistics of prediction intervals

- Understand how to conduct a forecast with prediction intervals in R


## Learning Objectives Tableau

- Apply Tableau's default forecasting

- Customize Tableau's forecasting

- Visualize decompositions and forecasts created in R

- Create advanced visualizations to demonstrate seasonality and overall trends in time series data



# R: Time Series Forecast and Prediction Interval

Last week we learned how to build a forecast from the components of the time series decomposition (Trend, Seasonality, and Residual). We made some relatively simple assumptions about how these components would behave in the future. R has many time series analysis and forecasting tools. Because the libraries containing the tools are open source and written by R users, the structure of the functions and object created by them may vary. We are going to start using a new library called `fpp3` that you will need to install if it isn't already installed. `fpp3` is a meta-library that loads a series of time series forecasting libraries that make time series analysis and forecasting much easier. The library `fpp3` was created as the companion to the textbook [Forecasting: Principles and Practice (3rd ed)](https://otexts.com/fpp3/)]. The main libraries we will be using are `fable` and `feasts`.  `fable` contains many time series models that you might want to use to understand and forecast data. `feasts` contains a set of `dplyr`-like tools to work with time series data. This set of packages makes it *very easy* to run models and extract the information you want.

The goal today is to look at prediction intervals, which are related to confidence intervals but pertain to your forecast.  



### Step 1: Load your data

First, let's load the time series data into R and set up your script (description, working directory, load packages).  We will continue using the carrot price data.  

```{r}
#| eval: false
#This lab...

library(tidyquant)
library(fpp3)

carrot <- tq_get(c("WPU01130212"),get = "economic.data",from="2007-08-01")
```

### Step 2: Convert your data into a time series object

Like last week, we need to convert our data into a time series dataframe called a `tsibble`:

```{r}
#| eval: false

#Prep data
carrot_ts <- carrot %>%
  select(date,price) %>% #select only the date and price variables
  mutate(date=yearmonth(date)) %>% #convert the date into yearmonth format so the models understand the unit of observation
  as_tsibble() #convert the data to a tsibble object - similar to a tibble or data.frame but for time series data
```

This will create a new time series `tibble` object called `carrot_ts.`

### Step 3: Tidy forecast workflow

Again, our objective is to build a forecast model and extract the key pieces of information, so that we can send them to Tableau.  One of the benefits of the `fpp3` package is that it simplifies model building process in a structure that is compatible with the pipe, `%>%`. We will recreate the forecasting model that we built in parts last week. Recall that we first decomposed the carrot price time series into `trend`, `seasonal`, and `random` components, and built a forecasting model based on each component, then put it all back together.^[I've included more information about the model in [week 2](../week_02/lab_01_week_02.html) of this unit lab notes.] That process can be called a workflow - a set of steps for completing a task. We will translate the workflow we built into the structure of the new package.

#### 3a: Define the model

We have the time series data prepared for modeling. Now, we need to define the model. We defined individual forecasts for each of the three components in week 2. We used the function, `forecast`, which uses an `exponential smoothing` method by default. We can be more explicit in defining an exponential smoothing model of each component.

```{r}
#| eval: false
#Fit the model
fit <- carrot_ts %>%
  model(my_ets=ETS(price ~ trend(method="A") + season(method="A") + error(method="A"))) #fit model
```

The function model is used to define the forecasting model.  In this case, we define an exponential smoothing model, `ETS()`, based on three components: `trend`, `season`, and `error`. The argument `method="A"` in each component tells the model that we want those components to be *additive* rather than multiplicative. Finally, we define the model as `my_ets`. In short, this defines the model that we built in parts in week 2. Inspecting `fit` shows that this just defines the model but doesn't do anything with it.^[You can extract model coefficient estimates using the command `tidy(fit)` if you need to extract them.] 

Note that `model` is a powerful function capable of specifying many models at once.  You may want to compare model fits or estimate models on several price series simultaneously.  See more information [here](https://fable.tidyverts.org/articles/fable.html).

#### 3b: Forecast the model

Now that we have specified the model, we need to actually run the forecast. We will use a function called `forecast()` from the `fabletools` library (related to `fable`).  However, this function is different from the previously used forecast function. When there are potential conflicts between functions with the same name from different libraries, you can specify the library, so R does not try to use the wrong one. We specify that we want to forecast our `ETS` model for 5 years. The function understands that you want 5 years worth of monthly forecasts (remember the data is stored as monthly data); this is equivalent to `h=60` because 60 months is 5 years.

```{r}
#| eval: false
#Forecast the model
carrot_forecast <- fit %>%
  fabletools::forecast(h="5 years") #forecast model for 5 years
```

Inspect `carrot_forecast` and you will see that it contains mean and variance information for each month of the 5 year forecast.  

#### 3c: Plot the forecast

Finally, you want to visualize your forecast. You can pass `carrot_forecast` into the function `autoplot()` that understands how to read forecast output. Note that `autoplot()` plots only the forecast by default. Adding the observed data `carrot_ts` tells the function to include the observed data in the plot.

```{r}
#| eval: false
#Plot the forecast
autoplot(carrot_forecast,carrot_ts) #forecast model for 5 years
```
You can see that the mean, the 80%, and the 90% prediction intervals are included.

See [Hyndman and Athanasopoulos](https://otexts.com/fpp3/a-tidy-forecasting-workflow.html) for more information on developing a workflow with these time series tools.

### Prediction intervals

The plot generated by `autoplot()` indicates that the model is estimating prediction intervals. There is a function `hilo()` from the `fable` library to extract them. However, this function creates a column with both upper and lower prediction intervals packed into a single variable. Fortunately, there is a function for separating the values into their own variables called `unpack_hilo()`. You need to specify the name of the variable; in this case `95%`.

```{r}
#| eval: false
#Extract prediction interval
carrot_forecast_out <- carrot_forecast %>%
  hilo(level = 95) %>% #extract 95% prediction interval
  unpack_hilo(cols = "95%") #unpack into own columns
```

### Preparing to export

Finally, we want to prepare the data for export to Tableau.  Recall that our original data had two variables: `date` and `price`.  Our tsibble `carrot_forecast_out` has `date` and `price`, but the `price` variable is a distribution rather than a value.  However, the variable `.mean` contains the forecast mean, so we can remove `price` and rename `.mean`. Remember that you can rename and select variables in the same command.

```{r}
#| eval: false
#Prepare data for export
part2 <- carrot_forecast_out %>%
  select(date,price=.mean,`95%_lower`,`95%_upper`)

to_export <- bind_rows(carrot_ts,part2)

write_csv(to_export,"carrot_forecast.csv")

```

{{< video https://youtu.be/KMrGAUcnM00 aspect-ratio="16x9" >}}

# Tableau

Tableau has its own forecasting features, but these are much less informative and flexible than what you ca do in R. Today we will show you how to use and customize Tableau’s forecasting features, how to create visualizations using your (improved) R forecasts, and we will show you how to create visualizations that show trends and cyclicality in your data — key components of your forecast!

## 1. Tableau’s Forecasting

Let’s load your carrot price data you exported from R into Tableau and check out Tableau’s forecasting features.

1. Once you are connected to the carrot price data, let’s create a filter for our entire workbook so that we only use more recent data (after our structural break) in the forecasting exercise.  

    - On the Data Source page, click `filter` in the top right.

  	- Filter Date to begin August 1, 2007

2. Open a new worksheet and plot the monthly carrot price data over time.  

3. Two ways to add a forecast - Right click or go to the `Analytics` tab on the left pane.  

Now you have added a forecast line that Tableau has decided is a good fit of your data. (Along with 95% confidence bands) Let’s explore this forecast.

1. Right click on your visualization and select `Forecast` -> `Describe Forecast...`  

  	- Did Tableau use the entire time period when constructing the forecast?

    	- What time period is Tableau forecasting for?

	- Does Tableau think this forecast is accurate?

  	- If you want to learn more about this description, click the link at the bottom of the window.

2. Click on `Models` at the top of the window.

  	- This gives you information about the forecasting model Tableau has applied, including how it is weighting values (past vs. more recent), and measures of “fit”.

  	- If you want to learn more about the Tableau forecasting models, click the link at the bottom of the window.

Now, let’s adjust Tableau’s recommended forecast as we see fit.

1. Right click on your visualization and select `Forecast` -> `Forecast Options...`

2. Adjust the forecast length by selecting `Exactly` or `Until`

3. Adjust the ignored periods (this is useful if your data only include part of a year, or if you have reason to believe the more recent data are not as useful) - what happens to the forecast as you adjust this?

4. Change the forecast model from `Automatic` to `Custom` and adjust the model parameters. Which do you like best?

5. Once you have created a forecast you are satisfied with, exit the popup window. Right click your worksheet tab and select `Duplicate as Crosstab`. Now you can easily see the values of your forecast.


Note that the initial forecast you saw was the one that Tableau determined to yield the highest quality prediction given your data, but it really was not a great prediction. R has much better forecasting capabilities, including more flexibility in the models you can apply, and more transparent algorithms. Best practice is to forecast in R, then visualize your forecast and its decomposition in Tableau.

## 2. Visualizing R Forecasts in Tableau

First, let’s visualize our decomposition:

1. Connect to the carrot price forecast data you exported in R. To keep everything in the same workbook, create a connection between these data and your original carrot price data (using the Date) variable

2. Plot your raw data

3. Add the trend line you calculated in R to the pane below this

4. Show the seasonality you calculated in R in a pane below this

5. Finally, show the residuals in the pane below this

6. You can also play with combining these figures as you see appropriate (e.g., I like to look at the trend line in the same pane as the actual data)

7. As an aside - let’s change the raw price data to a “moving average” using Tableau’s quick table calculation. Why is this moving average different from the one you calculated in R?


Next, let’s visualize our forecast:

1. Open a new worksheet and plot your carrot price data.

2. Add your forecasted data from R. Change the color of the forecasted data to clarify which is forecasted and which is observed.

And voila! You have both created a good forecast and visualized its components along with the forecast.

## 3. Additional Visualizations for Understanding Seasonality

I will now quickly walk you through some ideas for showing and identifying seasonality in your data, as well as separating seasonality from overall trends.

1. Line graph over month

  	- Gives you some idea of average trends month to month

2. Lines for each year over month

  	- Gives you some idea of month to month trends across years

3. Heat map

  	- Gives you some idea of months with larger and smaller prices across years

  	- Gives you some idea of months with larger changes in prices across years

4. Cycle map

  	- This is the best way of visualizing (within year) seasonality and larger trends (across years)