---
title: "Week 10: <br>Cross-Sectional Data Analysis"
format: 
  revealjs:
    theme: [night, ../../custom.scss]
    slide-number: c/t
    width: 1400
    # logo: path.png
    # center: TRUE
---

## Agenda 

Exploring your data 

Store segmentation example

Customer segmentation and mapping

Project 2 overview

<!-- example of big text fit to slide width -->

<!-- ::: {.r-fit-text} -->
<!-- Big Text -->
<!-- ::: -->

<!-- :::: {.columns style="text-align: center"} -->
<!-- ::: {.column width="40%"} -->
<!-- ::: -->
<!-- ::: {.column width="60%"} -->
<!-- ::: -->
<!-- :::: -->

# Exploring your data

## Exploratory data analysis

What do we mean when we say *explore your data*?

$\rightarrow$ Gain familiarity with the contents of the data

$\rightarrow$ Identify questions that can be answered with the data

$\rightarrow$ Generate summary statistics (average, variance, min, max)

$\rightarrow$ Plot distributions and correlations between variables

## Gain familiarity with your data {.scrollable}

A good data source will provide information about a dataset in the form of a **data dictionary**.

A data dictionary is a comprehensive guide that provides detailed information to the data analyst about the dataset being analyzed.

Can include:

- Variable names

- Data types

- Descriptions

- Possible values

- Missing value indication

- Data source

## 

<section>
<embed src="includes/Advan Weekly Patterns.pdf" width="900" height="700">
</section>

## Identify questions that could be asked

- Which stores have the greatest number of unique shoppers?

- What is the average length of time a shopper remains in a store?

- How far do shoppers travel to a store during a weekday?

- What time of day is the busiest time to shop on a Saturday and a Sunday?  

## Summary statistics {.scrollable}

Summary statistics provide an overview of the data's main characteristics.

They are important for understanding the data's scope and identifying possible outliers.

What summary statistics would we want to report if we were to answer the following question: 

**How do stores vary in terms of customer traffic and product diversity?**

## Summary statistics {.scrollable}

**How do stores vary in terms of customer traffic and product diversity?**

1. **Average number of unique customers (mean)**: Shows how many individual shoppers typically visit a store during the month. Stores with higher values likely serve a broader customer base or higher-traffic locations.

2. **Average product diversity (mean)**: Reflects the average number of distinct products sold per store. A higher number suggests broader assortments, while lower numbers could signal specialization (e.g., fuel-focused or small-format stores).

## Summary statistics {.scrollable}

**How do stores vary in terms of customer traffic and product diversity?**

3. **Range of unique customers and product diversity (min and max)**:

- Minimums may represent underperforming or rural locations.

- Maximums could indicate high-volume stores or those in dense areas.

4. **Standard deviation (variation)**: For both variables, this tells us how much stores differ from one another:

- A high standard deviation in unique customers suggests variation in store foot traffic — some serve many more shoppers than others.

- A high standard deviation in product diversity suggests variation in assortment strategy — from limited selection stores to large-format or multi-category stores.


# Plotting distributions and correlations

## Distributions {.scrollable}

Plotting data allows you to see relationships in the data that cannot be easily identified with summary statistics.

We plot *distributions* for a single variable:

- Allows you to see patterns, anomalies, and spot outliers in the data

- The shape of the distribution informs whether you will need to transform the data (e.g., take the log)

## Correlations

We plot *correlations* between two variables:

- Discover relationships between two variables and use this to inform a hypothesis

- Highly correlated data can be problematic and plotting correlations can detect these relationships

## What is `ggpairs()`?

The `ggpairs()` function comes from the `GGally` package in R and is a powerful tool for visualizing relationships between multiple variables at once.

Think of it as a matrix of plots that lets you:

- Quickly explore distributions of individual variables

- See pairwise relationships between variables

- Identify potential correlations, outliers, and redundancy

## Example: Store Segmentation {.scrollable}

I'm interested in using cluster analysis to segment the sales data by stores.

I believe the following variables capture differences in store behavior.

- **Unique visitors** (`customers`)
- **Total sales** (`sales`)
- **Product mix** (`products`)
- **Store scale** (`chain_size`)
- **Store type/specialization** (`fuel_share`)

I want to visualize these variables to see if they adequately capture differences between the stores. 

## I use `ggpairs()` to visualize the relationships between the variables {.scrollable}

`library(GGally)`

`ggpairs(final_dataset %>% select(customers, sales, products, chain_size, fuel_share))`

## It produces a grid with the following structure {.smaller}

|         | `customers` | `sales` | `products` | ... |
|----------|----------|----------|----------|----------|
`customers` | Histogram | Correlation | Correlation | ... |
`sales`| Scatterplot | Histogram | Correlation | ... |
`products` | Scatterplot | Scatterplot | Histogram | ... |
... | ... | ... | ... | ... | 

- Diagonal: Histograms or density plots for each individual variable

- Lower triangle: Scatterplots showing relationships between variable pairs

- Upper triangle: Correlation coefficients between each variable pair

##

![](includes/ggpairs_store_segment_levels.png){fig-align="center"}

## How to read this output {.scrollable}

The first thing I look at are the diagonals: How are my variables distributed?

- I see that the variables are skewed right^[A right-skewed or positive distribution means its tail is more pronounced on the right side than on the left.]
- I decide to "log transform" the variables (except fuel share)

My new set of potential cluster variables is now:

  - **Unique visitors** (`log_customers`)
  - **Total sales** (`log_sales`)
  - **Product mix** (`log_products`)
  - **Store scale** (`log_chain_size`)
  - **Store type/specialization** (`fuel_share`)


## 

![](includes/ggpairs_store_segment.png){fig-align="center"}


## 

![](includes/ggpairs_store_segment.png){fig-align="center"}

## How to read correlation coefficients {.smaller}

| Variable Pair                    | Corr    | Interpretation                                                                 |
|----------------------------------|---------|---------------------------------------------------------------------------------|
| `log_customers` ~ `log_sales`    | 0.741    | Strong positive relationship. Stores with more customers tend to generate more total sales (as expected). |
| `log_customers` ~ `log_products` | 0.453    | Stores with more product variety attract more customers.                        |
| `log_customers` ~ `log_chain_size` | 0.335  | Bigger chains tend to have more customers per store.                            |
| `log_sales ~ log_products`     | 0.44    | Stores with more diverse products tend to sell more overall. Suggests product variety drives revenue. |
| `log_sales ~ fuel_share`     | 0.413    | Stores with higher sales also have higher share coming from fuel. |
| `log_products` ~ `fuel_share`    | -0.114   | Slightly negative: stores that sell mostly fuel may offer fewer product types.  |

We want to make sure none of our correlations are close to 1, as that would indicate *collinearity*. If you find a perfectly collinear variable (or close to +/- 1), remove one. 

## Overall takaways {.smaller}

- Log transformations helped reduce extreme skew and made relationships between variables easier to see.
- Still a bit right-skewed even after log transformation.
- Most correlations are moderate and positive — indicating your clustering variables are related but not redundant.
- No obvious collinearity problems (no correlations near 1).
- No variable appears redundant — good news for clustering.
- There’s decent variation across stores, which is ideal for segmentation.

## Why this matters

Before running a segmentation algorithm like K-means, you want to:

- Check for multicollinearity — avoid overly redundant inputs
- Make sure variables are on similar scales (e.g., using log or standardization)
- Choose variables that add unique information about store behavior




# Customer segmentation

## [ESRI Tapestry Segmentation](https://doc.arcgis.com/en/esri-demographics/latest/regional-data/tapestry-segmentation.htm)

Uses cluster analysis on census demographic data (+ others) to define groups

![](includes/esri_tapestry.jpeg){fig-align="center"}


## Why segment your customers?

We live in a noisy world and crowded marketplace

People are getting better at ignoring and there are more niches

Increase the chances of of reaching the right customers with the right message at the right time

Increase sales, revenue, and hopefully profit


## Dimensions of customer segmentation

Identify customer personas

Customer stage - leads, prospects, existing customers

Customer demographics - age, gender, income, location, occupation

Customer behaviors - purchase history, web browsing activity

## Customer segmentation analysis

A common application of cluster analysis is to use sales data to divide customers into groups to improve target marketing.

Let's look at a case study. . .

## MetLife case study

```{=html}
<iframe width="100%" height="500" src="https://d3.harvard.edu/platform-rctom/submission/metlife-a-case-study-in-customer-segmentation/"></iframe>
```

<!-- ## How do you know if you are achieving your goal? -->

<!-- ::: .columns -->

<!-- ::: {.column width="45%"} -->
<!-- Measuring Key Performance Indicators (KPIs) -->

<!-- Conversion rates - online click through -->

<!-- Customer loyalty - rates of repeat purchases -->

<!-- ::: -->

<!-- ::: {.column width="50%"} -->

<!-- ![](https://images.shiksha.com/mediadata/ugcDocuments/images/wordpressImages/2023_02_Clickthrough-rate-1.jpg) -->

<!-- ::: -->
<!-- ::: -->

## In lab this week

- Perform cluster analysis by stores in R

- Map store location data in Tableau and assign cluster information

# Project 2

## Project 2: Overview {.scrollable}

Use the data provided to:

- Perform an exploratory data analysis 

- Assemble summary statistics

- Analyze spatial patterns, correlations, etc.

- Construct visualizations

You must:

- Conduct market segmentation analysis via clustering (customer, store, or product)

- Label clusters based on characteristics

- Develop a simple marketing strategy to target clusters

## Project 2: Data

Overview: Transaction-level data from convenience stores across the U.S. during July of 2023

A *transaction* is defined as a purchase incident made by a shopper. (Think: receipt)

Transaction-level data includes information about the store where they made the purchase, the price and quantity of the products they purchased, and details about the items they purchased.


##

![](includes/data_schema.png){fig-align="center"}

## Project 2: Data {.scrollable}

"shopper_info.csv"

- This is the core file that contains information about the shopper and each transaction they made during the month of July 2023.

"gtin.csv"

- You will link this file with "shopper_info" based on the variable gtin. 

- GTIN stands for "Global Trade Item Number" and is similar to an SKU or UPC (i.e., barcode).

"store_info.csv"

- This file contains the store details and can be linked with the "shopper_info" using the variable store_id.

## Project 2: Types of segmentations
::: .columns

::: {.column width="45%"}
By store:

- Which stores are similar by mix of products sold?

- Which stores are similar by sales?

By product:

- Which products are similar? 

:::

::: {.column width="45%"}
By shopper:

- Which shoppers are similar based on where they shop?

- Which shoppers are similar based on what they purchase?

:::

:::


## Summary

Explore your data: understanding your data, identifying questions, descriptive statistics, plotting distributions, plotting correlations



<!--
## Methods overview

:::: {.columns style="text-align: left"}
::: {.column width="50%"}
**Unsupervised Learning**

To discover hidden patterns and relationships within the data

Identify structure or patterns on its own given an unlabeled dataset

Good for exploring relationships and generating explanatory questions
:::
::: {.column width="50%"}
**Supervised Learning**

To explain relationships between inputs and outputs

Models are trained on labeled data (outputs and inputs known)

Good for explaining relationships and predicting new outcomes

:::
::::

# Cross-Sectional Data Analysis

## Cluster analysis

Last week, we discussed **cluster analysis** 

Cluster analysis is a form of *unsupervised learning* 

It provides a systematic method to look for patterns in data.

## Knowledge check

We discussed k-means clustering in class, and in lab. What is the main goal of the k-means clustering algorithm?

A) To minimize the distance between all data points in the dataset.

B) To minimize the distance between each data point and its assigned centroid.

C) To maximize the distance between each data point and all other data points.

D) To maximize the distance between each data point and its assigned centroid.

-->

<!-- OLD SLIDES THAT HAVE BEEN COMMENTED OUT OR MOVED TO UNIT 02 WEEK 01
![](includes/customer_segmentation.png)

## How does cluster analysis work? {.scrollable}

[K-means clustering](https://youtu.be/4b5d3muPQmA)

1. Choose the number of clusters (k) that you want to identify in the data.

2. Randomly initialize the k cluster centroids (points in space) within the data range.

3. Assign each data point to the nearest centroid, based on the Euclidean distance between the point and each centroid.

4. Calculate the mean (centroid) of each cluster based on the data points assigned to it.

5. Update the cluster centroids to be the means of the data points assigned to them.

6. Repeat steps 3-5 until convergence (when the cluster assignments no longer change or a maximum number of iterations is reached).

Usually, we repeat this whole process a number of times and choose the group assignment that minimizes the overall variance

After clustering, summarize attributes of the clusters to understand the groups



# Supervised Learning

## Regression

Used to estimate relationships between inputs (independent, explanatory) and outputs (dependent, outcome)

![](includes/ols.webp)

## Example: Ice Cream Sales and Temperature

![](includes/ice_cream_temp.jpeg)

## Classification

Problem: we need to classify data into discrete units (e.g., images, product types, sentiment)^[Can also be used on continuous data]

We have some units labeled and know information about them (cats vs dogs)

We want to develop a model to classify new units based on observable attributes

## Wildfire Hazard Potential

![](includes/whp.jpeg)

## Spam email

![](includes/spam.webp)

## Decision Tree Classification

Classification as a sequence of binary decisions

![](includes/decision_tree.png)

## How it works?

1. Identify the variable that provides the most information gain when split on.

2. Split the dataset based on the chosen feature into two or more subsets.

3. Repeat steps 2 and 3 for each subset until a stopping criterion is met, such as reaching a maximum depth or the subsets being too small to split further.

4. At each leaf node, assign a class label based on the majority class of the data points in that node.

## Random Forest

Grow many decision trees using independent subsets of the data

Use the same criteria for constructing each tree

Average the prediction of all trees

This approach avoids over-fitting the data and improves accuracy when used to predict the class of new data

## Knowledge check

What is the main difference between supervised and unsupervised learning?

A. Supervised learning requires labeled data, while unsupervised learning does not.

B. Unsupervised learning requires labeled data, while supervised learning does not.

C. Both supervised and unsupervised learning require labeled data.

D. There is no difference between supervised and unsupervised learning.

## Summary 

Unsupervised learning methods like clustering can help you learn about patterns in your data

Supervised learning methods like regression and classification can help you explain relationships and predict outcomes of new data

-->




